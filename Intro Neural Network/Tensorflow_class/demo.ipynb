{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Classification Example with TensorFlow\n",
    "\n",
    "This notebook is a companion of [A Visual and Interactive Guide to the Basics of Neural Networks](https://jalammar.github.io/visual-interactive-guide-basics-neural-networks/).\n",
    "\n",
    "This is an example of how to do classification on a simple dataset in TensorFlow. Basically, we're building a model to help a friend choose a house to buy. She has given us the table below of houses and whether she likes them or not. We're to build a model that takes a house area and number of bathrooms as input, and outputs a prediction of whether she would like the house or not.\n",
    "\n",
    "| Area (sq ft) (x1) | Bathrooms (x2) | Label (y) |\n",
    " | --- | --- | --- |\n",
    " | 2,104 |  3 | Good |\n",
    " | 1,600 |  3 | Good |\n",
    " | 2,400 |  3 | Good |\n",
    " | 1,416 | \t2 | Bad |\n",
    " | 3,000 | \t4 | Bad |\n",
    " | 1,985 | \t4 | Good |\n",
    " | 1,534 | \t3 | Bad |\n",
    " | 1,427 | \t3 | Good |\n",
    " | 1,380 | \t3 | Good |\n",
    " | 1,494 | \t3 | Good |\n",
    " \n",
    " \n",
    " \n",
    " We'll start by loading our favorite libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline               \n",
    "import pandas as pd              # A beautiful library to help us work with data as tables\n",
    "import numpy as np               # So we can use number matrices. Both pandas and TensorFlow need it. \n",
    "import matplotlib.pyplot as plt  # Visualize the things\n",
    "import tensorflow as tf          # Fire from the gods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll then load the house data CSV. Pandas is an incredible library that gives us great flexibility in dealing with table-like data. We load tables (or csv files, or excel sheets) into a \"data frame\", and process it however we like. You can think of it as a programatic way to do a lot of the things you previously did with Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     area  bathrooms\n",
       "0  2104.0        3.0\n",
       "1  1600.0        3.0\n",
       "2  2400.0        3.0\n",
       "3  1416.0        2.0\n",
       "4  3000.0        4.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>area</th>\n      <th>bathrooms</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2104.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1600.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2400.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1416.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3000.0</td>\n      <td>4.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "dataframe = pd.read_csv(\"data.csv\") # Let's have Pandas load our dataset as a dataframe\n",
    "dataframe = dataframe.drop([\"index\", \"price\", \"sq_price\"], axis=1) # Remove columns we don't care about\n",
    "dataframe = dataframe[0:30] # We'll only use the first 10 rows of the dataset in this example\n",
    "dataframe.head() # Let's have the notebook show us how the dataframe looks now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The dataframe now only has the features. Let's introduce the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     area  bathrooms  y1\n",
       "0  2104.0        3.0   1\n",
       "1  1600.0        3.0   1\n",
       "2  2400.0        3.0   0\n",
       "3  1416.0        2.0   1\n",
       "4  3000.0        4.0   1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>area</th>\n      <th>bathrooms</th>\n      <th>y1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2104.0</td>\n      <td>3.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1600.0</td>\n      <td>3.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2400.0</td>\n      <td>3.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1416.0</td>\n      <td>2.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3000.0</td>\n      <td>4.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "dataframe.loc[:, (\"y1\")] = np.random.randint(0,2,30)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     area  bathrooms  y1  y2\n",
       "0  2104.0        3.0   1   0\n",
       "1  1600.0        3.0   1   0\n",
       "2  2400.0        3.0   0   1\n",
       "3  1416.0        2.0   1   0\n",
       "4  3000.0        4.0   1   0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>area</th>\n      <th>bathrooms</th>\n      <th>y1</th>\n      <th>y2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2104.0</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1600.0</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2400.0</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1416.0</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3000.0</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    " # This is our friend's list of which houses she liked # 1 = good, 0 = bad\n",
    "dataframe.loc[:, (\"y2\")] = dataframe[\"y1\"] == 0           # y2 is the negation of y1\n",
    "dataframe.loc[:, (\"y2\")] = dataframe[\"y2\"].astype(int)    # Turn TRUE/FALSE values into 1/0\n",
    "# y2 means we don't like a house\n",
    "# (Yes, it's redundant. But learning to do it this way opens the door to Multiclass classification)\n",
    "dataframe.head() # How is our dataframe looking now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now that we have all our data in the dataframe, we'll need to shape it in matrices to feed it to TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inputX = dataframe.loc[:, ['area', 'bathrooms']].values\n",
    "inputY = dataframe.loc[:, [\"y1\", \"y2\"]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now our input matrix looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[2.104e+03, 3.000e+00],\n",
       "       [1.600e+03, 3.000e+00],\n",
       "       [2.400e+03, 3.000e+00],\n",
       "       [1.416e+03, 2.000e+00],\n",
       "       [3.000e+03, 4.000e+00],\n",
       "       [1.985e+03, 4.000e+00],\n",
       "       [1.534e+03, 3.000e+00],\n",
       "       [1.427e+03, 3.000e+00],\n",
       "       [1.380e+03, 3.000e+00],\n",
       "       [1.494e+03, 3.000e+00],\n",
       "       [1.940e+03, 4.000e+00],\n",
       "       [2.000e+03, 3.000e+00],\n",
       "       [1.890e+03, 3.000e+00],\n",
       "       [4.478e+03, 5.000e+00],\n",
       "       [1.268e+03, 3.000e+00],\n",
       "       [2.300e+03, 4.000e+00],\n",
       "       [1.320e+03, 2.000e+00],\n",
       "       [1.236e+03, 3.000e+00],\n",
       "       [2.609e+03, 4.000e+00],\n",
       "       [3.031e+03, 4.000e+00],\n",
       "       [1.767e+03, 3.000e+00],\n",
       "       [1.888e+03, 2.000e+00],\n",
       "       [1.604e+03, 3.000e+00],\n",
       "       [1.962e+03, 4.000e+00],\n",
       "       [3.890e+03, 3.000e+00],\n",
       "       [1.100e+03, 3.000e+00],\n",
       "       [1.458e+03, 3.000e+00],\n",
       "       [2.526e+03, 3.000e+00],\n",
       "       [2.200e+03, 3.000e+00],\n",
       "       [2.637e+03, 3.000e+00]])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "inputX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And our labels matrix looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1]])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "inputY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare some parameters for the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.000001\n",
    "training_epochs = 1000\n",
    "display_step = 10\n",
    "n_samples = inputY.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now to define the TensorFlow operations. Notice that this is a declaration step where we tell TensorFlow how the prediction is calculated. If we execute it, no calculation would be made. It would just acknowledge that it now knows how to do the operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We select the TF1 compatibility \n",
    "\n",
    "import tensorflow.compat.v1 as v1\n",
    "#v1.enable_eager_execution()\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = v1.placeholder(v1.float32, [None, 2])   # Okay TensorFlow, we'll feed you an array of examples. Each example will\n",
    "                                            # be an array of two float values (area, and number of bathrooms).\n",
    "                                            # \"None\" means we can feed you any number of examples\n",
    "                                            # Notice we haven't fed it the values yet\n",
    "            \n",
    "W = v1.Variable(tf.zeros([2, 2]))           # Maintain a 2 x 2 float matrix for the weights that we'll keep updating \n",
    "                                            # through the training process (make them all zero to begin with)\n",
    "    \n",
    "b = v1.Variable(tf.zeros([2]))              # Also maintain two bias values\n",
    "\n",
    "y_values = v1.add(tf.matmul(x, W), b)       # The first step in calculating the prediction would be to multiply\n",
    "                                            # the inputs matrix by the weights matrix then add the biases\n",
    "    \n",
    "y = v1.nn.softmax(y_values)                 # Then we use softmax as an \"activation function\" that translates the\n",
    "                                            # numbers outputted by the previous layer into probability form\n",
    "    \n",
    "y_ = v1.placeholder(tf.float32, [None,2])   # For training purposes, we'll also feed you a matrix of labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's specify our cost function and use Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Cost function: Mean squared error\n",
    "cost = tf.reduce_sum(tf.pow(y_ - y, 2))/(2*n_samples)\n",
    "# Gradient descent\n",
    "optimizer = v1.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize variabls and tensorflow session\n",
    "init = v1.initialize_all_variables()\n",
    "sess = v1.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Drum roll*\n",
    "\n",
    "And now for the actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training step: 0000 cost= 0.123911470\n",
      "Training step: 0010 cost= 0.123911470\n",
      "Training step: 0020 cost= 0.123911455\n",
      "Training step: 0030 cost= 0.123911448\n",
      "Training step: 0040 cost= 0.123911448\n",
      "Training step: 0050 cost= 0.123911448\n",
      "Training step: 0060 cost= 0.123911440\n",
      "Training step: 0070 cost= 0.123911433\n",
      "Training step: 0080 cost= 0.123911433\n",
      "Training step: 0090 cost= 0.123911433\n",
      "Training step: 0100 cost= 0.123911418\n",
      "Training step: 0110 cost= 0.123911418\n",
      "Training step: 0120 cost= 0.123911418\n",
      "Training step: 0130 cost= 0.123911418\n",
      "Training step: 0140 cost= 0.123911403\n",
      "Training step: 0150 cost= 0.123911403\n",
      "Training step: 0160 cost= 0.123911403\n",
      "Training step: 0170 cost= 0.123911403\n",
      "Training step: 0180 cost= 0.123911388\n",
      "Training step: 0190 cost= 0.123911388\n",
      "Training step: 0200 cost= 0.123911388\n",
      "Training step: 0210 cost= 0.123911388\n",
      "Training step: 0220 cost= 0.123911381\n",
      "Training step: 0230 cost= 0.123911373\n",
      "Training step: 0240 cost= 0.123911373\n",
      "Training step: 0250 cost= 0.123911373\n",
      "Training step: 0260 cost= 0.123911373\n",
      "Training step: 0270 cost= 0.123911358\n",
      "Training step: 0280 cost= 0.123911351\n",
      "Training step: 0290 cost= 0.123911358\n",
      "Training step: 0300 cost= 0.123911336\n",
      "Training step: 0310 cost= 0.123911336\n",
      "Training step: 0320 cost= 0.123911321\n",
      "Training step: 0330 cost= 0.123911321\n",
      "Training step: 0340 cost= 0.123911321\n",
      "Training step: 0350 cost= 0.123911321\n",
      "Training step: 0360 cost= 0.123911321\n",
      "Training step: 0370 cost= 0.123911306\n",
      "Training step: 0380 cost= 0.123911306\n",
      "Training step: 0390 cost= 0.123911306\n",
      "Training step: 0400 cost= 0.123911306\n",
      "Training step: 0410 cost= 0.123911291\n",
      "Training step: 0420 cost= 0.123911291\n",
      "Training step: 0430 cost= 0.123911291\n",
      "Training step: 0440 cost= 0.123911276\n",
      "Training step: 0450 cost= 0.123911284\n",
      "Training step: 0460 cost= 0.123911276\n",
      "Training step: 0470 cost= 0.123911276\n",
      "Training step: 0480 cost= 0.123911276\n",
      "Training step: 0490 cost= 0.123911262\n",
      "Training step: 0500 cost= 0.123911262\n",
      "Training step: 0510 cost= 0.123911262\n",
      "Training step: 0520 cost= 0.123911247\n",
      "Training step: 0530 cost= 0.123911247\n",
      "Training step: 0540 cost= 0.123911247\n",
      "Training step: 0550 cost= 0.123911247\n",
      "Training step: 0560 cost= 0.123911239\n",
      "Training step: 0570 cost= 0.123911232\n",
      "Training step: 0580 cost= 0.123911232\n",
      "Training step: 0590 cost= 0.123911209\n",
      "Training step: 0600 cost= 0.123911209\n",
      "Training step: 0610 cost= 0.123911209\n",
      "Training step: 0620 cost= 0.123911209\n",
      "Training step: 0630 cost= 0.123911209\n",
      "Training step: 0640 cost= 0.123911195\n",
      "Training step: 0650 cost= 0.123911195\n",
      "Training step: 0660 cost= 0.123911195\n",
      "Training step: 0670 cost= 0.123911180\n",
      "Training step: 0680 cost= 0.123911187\n",
      "Training step: 0690 cost= 0.123911180\n",
      "Training step: 0700 cost= 0.123911180\n",
      "Training step: 0710 cost= 0.123911172\n",
      "Training step: 0720 cost= 0.123911165\n",
      "Training step: 0730 cost= 0.123911165\n",
      "Training step: 0740 cost= 0.123911157\n",
      "Training step: 0750 cost= 0.123911165\n",
      "Training step: 0760 cost= 0.123911150\n",
      "Training step: 0770 cost= 0.123911150\n",
      "Training step: 0780 cost= 0.123911142\n",
      "Training step: 0790 cost= 0.123911135\n",
      "Training step: 0800 cost= 0.123911135\n",
      "Training step: 0810 cost= 0.123911135\n",
      "Training step: 0820 cost= 0.123911135\n",
      "Training step: 0830 cost= 0.123911120\n",
      "Training step: 0840 cost= 0.123911120\n",
      "Training step: 0850 cost= 0.123911120\n",
      "Training step: 0860 cost= 0.123911113\n",
      "Training step: 0870 cost= 0.123911098\n",
      "Training step: 0880 cost= 0.123911098\n",
      "Training step: 0890 cost= 0.123911090\n",
      "Training step: 0900 cost= 0.123911083\n",
      "Training step: 0910 cost= 0.123911083\n",
      "Training step: 0920 cost= 0.123911083\n",
      "Training step: 0930 cost= 0.123911068\n",
      "Training step: 0940 cost= 0.123911068\n",
      "Training step: 0950 cost= 0.123911068\n",
      "Training step: 0960 cost= 0.123911068\n",
      "Training step: 0970 cost= 0.123911068\n",
      "Training step: 0980 cost= 0.123911053\n",
      "Training step: 0990 cost= 0.123911053\n",
      "Optimization Finished!\n",
      "Training cost= 0.123911045 W= [[ 4.2887004e-05 -4.2886946e-05]\n",
      " [ 2.6641794e-05 -2.6641794e-05]] b= [ 1.1505452e-05 -1.1505452e-05] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(training_epochs):  \n",
    "    sess.run(optimizer, feed_dict={x: inputX, y_: inputY}) # Take a gradient descent step using our inputs and labels\n",
    "\n",
    "    # That's all! The rest of the cell just outputs debug messages. \n",
    "    # Display logs per epoch step\n",
    "    if (i) % display_step == 0:\n",
    "        cc = sess.run(cost, feed_dict={x: inputX, y_:inputY})\n",
    "        print(\"Training step:\", '%04d' % (i), \"cost=\", \"{:.9f}\".format(cc)) #, \\\"W=\", sess.run(W), \"b=\", sess.run(b)\n",
    "\n",
    "print(\"Optimization Finished!\")\n",
    "training_cost = sess.run(cost, feed_dict={x: inputX, y_: inputY})\n",
    "print(\"Training cost=\", training_cost, \"W=\", sess.run(W), \"b=\", sess.run(b), '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now the training is done. TensorFlow is now holding on to our trained model (Which is basically just the defined operations, plus the variables W and b that resulted from the training process).\n",
    "\n",
    "Is a cost value of 0.109537 good or bad? I have no idea. At least it's better than the first cost value of 0.114958666. Let's use the model on our dataset to see how it does, though:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.54504037, 0.4549596 ],\n",
       "       [0.53430134, 0.4656987 ],\n",
       "       [0.5513286 , 0.44867137],\n",
       "       [0.53035897, 0.469641  ],\n",
       "       [0.5640359 , 0.4359641 ],\n",
       "       [0.5425214 , 0.4574786 ],\n",
       "       [0.53289247, 0.46710756],\n",
       "       [0.5306073 , 0.46939278],\n",
       "       [0.52960306, 0.47039694],\n",
       "       [0.53203833, 0.46796167],\n",
       "       [0.5415633 , 0.45843676],\n",
       "       [0.5428275 , 0.4571725 ],\n",
       "       [0.5404851 , 0.45951492],\n",
       "       [0.59493035, 0.4050697 ],\n",
       "       [0.52720916, 0.47279087],\n",
       "       [0.54921913, 0.45078084],\n",
       "       [0.5283075 , 0.4716925 ],\n",
       "       [0.52652496, 0.47347507],\n",
       "       [0.555772  , 0.44422793],\n",
       "       [0.56468964, 0.43531036],\n",
       "       [0.53786373, 0.46213627],\n",
       "       [0.54042923, 0.45957077],\n",
       "       [0.5343867 , 0.46561328],\n",
       "       [0.54203176, 0.4579683 ],\n",
       "       [0.5826943 , 0.41730574],\n",
       "       [0.52361596, 0.476384  ],\n",
       "       [0.5312695 , 0.46873057],\n",
       "       [0.5540005 , 0.44599947],\n",
       "       [0.5470815 , 0.4529185 ],\n",
       "       [0.5563518 , 0.44364825]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "sess.run(y, feed_dict={x: inputX })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So It's guessing they're all good houses. That makes it get 7/10 correct. Not terribly impressive. A model with a hidden layer should do better, I guess."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Btw, this is how I calculated the softmax values in the post:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.26894143, 0.7310586 ], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "sess.run(tf.nn.softmax([1., 2.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('deep': conda)",
   "language": "python",
   "name": "python38564bitdeepconda1f145d0de5544abc80c383a418c49c62"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}